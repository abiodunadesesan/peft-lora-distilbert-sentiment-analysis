{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "PEFT technique: LoRA (Low-Rank Adaptation)\n",
    "Model: distilbert-base-uncased using AutoModelForSequenceClassification (binary classification)\n",
    "Evaluation approach: Hugging Face Trainer with evaluate metrics (accuracy + weighted F1)\n",
    "Fine-tuning dataset: imdb dataset from Hugging Face datasets library (subsampled for faster training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "!pip -q install peft datasets transformers accelerate\n",
    "\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, AutoPeftModelForSequenceClassification\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2000 | Test size: 1000\n",
      "There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. \n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "train_ds = dataset[\"train\"].shuffle(seed=42).select(range(2000))\n",
    "test_ds  = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "print(\"Train size:\", len(train_ds), \"| Test size:\", len(test_ds))\n",
    "print(train_ds[0][\"text\"][:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b53bcb395c403bb5c157bcbf7f9f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True)\n",
    "\n",
    "train_tok = train_ds.map(tokenize, batched=True)\n",
    "test_tok  = test_ds.map(tokenize, batched=True)\n",
    "\n",
    "train_tok = train_tok.remove_columns([\"text\"])\n",
    "test_tok  = test_tok.remove_columns([\"text\"])\n",
    "\n",
    "train_tok = train_tok.rename_column(\"label\", \"labels\")\n",
    "test_tok  = test_tok.rename_column(\"label\", \"labels\")\n",
    "\n",
    "train_tok.set_format(\"torch\")\n",
    "test_tok.set_format(\"torch\")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "base_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = float((preds == labels).mean())\n",
    "\n",
    "    f1s = []\n",
    "    supports = []\n",
    "    for cls in [0, 1]:\n",
    "        tp = np.sum((preds == cls) & (labels == cls))\n",
    "        fp = np.sum((preds == cls) & (labels != cls))\n",
    "        fn = np.sum((preds != cls) & (labels == cls))\n",
    "\n",
    "        precision = tp / (tp + fp + 1e-12)\n",
    "        recall    = tp / (tp + fn + 1e-12)\n",
    "        f1        = 2 * precision * recall / (precision + recall + 1e-12)\n",
    "\n",
    "        support = np.sum(labels == cls)\n",
    "\n",
    "        f1s.append(f1)\n",
    "        supports.append(support)\n",
    "\n",
    "    weighted_f1 = float((f1s[0]*supports[0] + f1s[1]*supports[1]) / (supports[0] + supports[1] + 1e-12))\n",
    "\n",
    "    return {\"accuracy\": acc, \"f1\": weighted_f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE RESULTS: {'eval_loss': 0.6969956159591675, 'eval_accuracy': 0.393, 'eval_f1': 0.3873352169419138, 'eval_runtime': 16.6264, 'eval_samples_per_second': 60.145, 'eval_steps_per_second': 3.789}\n"
     ]
    }
   ],
   "source": [
    "args_base = TrainingArguments(\n",
    "    output_dir=\"/tmp/baseline_eval\",\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_strategy=\"no\",\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer_base = Trainer(\n",
    "    model=base_model,\n",
    "    args=args_base,\n",
    "    eval_dataset=test_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "baseline_results = trainer_base.evaluate()\n",
    "print(\"BASELINE RESULTS:\", baseline_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,331,716 || all params: 67,694,596 || trainable%: 1.967241225577297\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    target_modules=[\"q_lin\", \"v_lin\"]\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(base_model, lora_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 01:30, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>0.318441</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.861895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT RESULTS (after training): {'eval_loss': 0.31844109296798706, 'eval_accuracy': 0.862, 'eval_f1': 0.8618954876396948, 'eval_runtime': 17.562, 'eval_samples_per_second': 56.941, 'eval_steps_per_second': 7.118, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "args_peft = TrainingArguments(\n",
    "    output_dir=\"/tmp/peft_run\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer_peft = Trainer(\n",
    "    model=peft_model,\n",
    "    args=args_peft,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=test_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer_peft.train()\n",
    "peft_results = trainer_peft.evaluate()\n",
    "print(\"PEFT RESULTS (after training):\", peft_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7e8a663",
   "metadata": {},
   "source": [
    "###  ⚠️ IMPORTANT ⚠️\n",
    "\n",
    "Due to workspace storage constraints, you should not store the model weights in the same directory but rather use `/tmp` to avoid workspace crashes which are irrecoverable.\n",
    "Ensure you save it in /tmp always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved files: ['adapter_model.bin', 'tokenizer_config.json', 'vocab.txt', 'adapter_config.json', 'README.md', 'tokenizer.json', 'special_tokens_map.json']\n"
     ]
    }
   ],
   "source": [
    "peft_model.save_pretrained(\"/tmp/peft_adapter\")\n",
    "tokenizer.save_pretrained(\"/tmp/peft_adapter\")\n",
    "print(\"Saved files:\", os.listdir(\"/tmp/peft_adapter\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELOADED PEFT RESULTS: {'eval_loss': 0.31844112277030945, 'eval_accuracy': 0.862, 'eval_f1': 0.8618954876396948, 'eval_runtime': 19.0949, 'eval_samples_per_second': 52.37, 'eval_steps_per_second': 3.299}\n",
      "\n",
      "===== COMPARISON =====\n",
      "Baseline: {'eval_loss': 0.6969956159591675, 'eval_accuracy': 0.393, 'eval_f1': 0.3873352169419138, 'eval_runtime': 16.6264, 'eval_samples_per_second': 60.145, 'eval_steps_per_second': 3.789}\n",
      "Fine-tuned: {'eval_loss': 0.31844109296798706, 'eval_accuracy': 0.862, 'eval_f1': 0.8618954876396948, 'eval_runtime': 17.562, 'eval_samples_per_second': 56.941, 'eval_steps_per_second': 7.118, 'epoch': 1.0}\n",
      "Reloaded: {'eval_loss': 0.31844112277030945, 'eval_accuracy': 0.862, 'eval_f1': 0.8618954876396948, 'eval_runtime': 19.0949, 'eval_samples_per_second': 52.37, 'eval_steps_per_second': 3.299}\n"
     ]
    }
   ],
   "source": [
    "loaded_model = AutoPeftModelForSequenceClassification.from_pretrained(\"/tmp/peft_adapter\")\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "trainer_loaded = Trainer(\n",
    "    model=loaded_model,\n",
    "    args=args_base,\n",
    "    eval_dataset=test_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "loaded_results = trainer_loaded.evaluate()\n",
    "print(\"RELOADED PEFT RESULTS:\", loaded_results)\n",
    "\n",
    "print(\"\\n===== COMPARISON =====\")\n",
    "print(\"Baseline:\", baseline_results)\n",
    "print(\"Fine-tuned:\", peft_results)\n",
    "print(\"Reloaded:\", loaded_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied adapter to: ./peft_adapter\n",
      "Files: ['adapter_model.bin', 'tokenizer_config.json', 'vocab.txt', 'adapter_config.json', 'README.md', 'tokenizer.json', 'special_tokens_map.json']\n"
     ]
    }
   ],
   "source": [
    "dst = \"./peft_adapter\"\n",
    "src = \"/tmp/peft_adapter\"\n",
    "\n",
    "if os.path.exists(dst):\n",
    "    shutil.rmtree(dst)\n",
    "\n",
    "shutil.copytree(src, dst)\n",
    "print(\"Copied adapter to:\", dst)\n",
    "print(\"Files:\", os.listdir(dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5f07f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9009c2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
